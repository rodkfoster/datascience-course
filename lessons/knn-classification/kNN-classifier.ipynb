{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "#  K-Nearest Neighbors\n",
    "\n",
    "_Authors: Alex Sherman (DC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will get an intuitive and practical feel for the **k-Nearest Neighbors** model. \n",
    "\n",
    "- kNN is a **non-parametric model**, meaning it is non-linear. So, the model is not represented as an equation with parameters (e.g. the $\\beta$ values in linear regression).\n",
    "<br>\n",
    "\n",
    "<a id=\"k-nearest-neighbors-knn-classification\"></a>\n",
    "\n",
    "## K-Nearest Neighbors (KNN) Classification\n",
    "---\n",
    "\n",
    "K-nearest neighbors classification is (as its name implies) a classification model that uses the \"K\" most similar observations in order to make a prediction.\n",
    "\n",
    "KNN is a supervised learning method; therefore, the training data must have known target values.\n",
    "\n",
    "The process of of prediction using KNN is fairly straightforward:\n",
    "\n",
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the data that are \"nearest\" to the measurements of the unknown iris.\n",
    "    - Euclidian distance is often used as the distance metric, but other metrics are allowed.\n",
    "3. Use the most popular response value from the K \"nearest neighbors\" as the predicted response value for the unknown Target Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.949682</td>\n",
       "      <td>1.114303</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.682099</td>\n",
       "      <td>1.032336</td>\n",
       "      <td>0.943534</td>\n",
       "      <td>0.963422</td>\n",
       "      <td>1.071960</td>\n",
       "      <td>1.158251</td>\n",
       "      <td>1.362725</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.257085</td>\n",
       "      <td>0.291554</td>\n",
       "      <td>0.229645</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.256121</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.288982</td>\n",
       "      <td>0.293738</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.441398</td>\n",
       "      <td>0.170924</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.315307</td>\n",
       "      <td>0.262389</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>0.365157</td>\n",
       "      <td>0.639693</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.742358</td>\n",
       "      <td>0.942071</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>0.515010</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.784407</td>\n",
       "      <td>0.866306</td>\n",
       "      <td>0.934340</td>\n",
       "      <td>1.222623</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.940475</td>\n",
       "      <td>1.118486</td>\n",
       "      <td>0.813264</td>\n",
       "      <td>0.676835</td>\n",
       "      <td>1.035824</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>1.065500</td>\n",
       "      <td>1.165556</td>\n",
       "      <td>1.375368</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.163295</td>\n",
       "      <td>1.307904</td>\n",
       "      <td>1.028340</td>\n",
       "      <td>0.834317</td>\n",
       "      <td>1.198270</td>\n",
       "      <td>1.123060</td>\n",
       "      <td>1.134852</td>\n",
       "      <td>1.283156</td>\n",
       "      <td>1.383173</td>\n",
       "      <td>1.504832</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.721779</td>\n",
       "      <td>1.833757</td>\n",
       "      <td>1.722725</td>\n",
       "      <td>1.634884</td>\n",
       "      <td>1.650050</td>\n",
       "      <td>1.666902</td>\n",
       "      <td>1.713342</td>\n",
       "      <td>1.785420</td>\n",
       "      <td>1.885690</td>\n",
       "      <td>1.893950</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               WTT          PTI          EQW          SBI          LQE  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.949682     1.114303     0.834127     0.682099     1.032336   \n",
       "std       0.289635     0.257085     0.291554     0.229645     0.243413   \n",
       "min       0.174412     0.441398     0.170924     0.045027     0.315307   \n",
       "25%       0.742358     0.942071     0.615451     0.515010     0.870855   \n",
       "50%       0.940475     1.118486     0.813264     0.676835     1.035824   \n",
       "75%       1.163295     1.307904     1.028340     0.834317     1.198270   \n",
       "max       1.721779     1.833757     1.722725     1.634884     1.650050   \n",
       "\n",
       "               QWG          FDJ          PJF          HQE          NXJ  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.943534     0.963422     1.071960     1.158251     1.362725   \n",
       "std       0.256121     0.255118     0.288982     0.293738     0.204225   \n",
       "min       0.262389     0.295228     0.299476     0.365157     0.639693   \n",
       "25%       0.761064     0.784407     0.866306     0.934340     1.222623   \n",
       "50%       0.941502     0.945333     1.065500     1.165556     1.375368   \n",
       "75%       1.123060     1.134852     1.283156     1.383173     1.504832   \n",
       "max       1.666902     1.713342     1.785420     1.885690     1.893950   \n",
       "\n",
       "       TARGET CLASS  \n",
       "count    1000.00000  \n",
       "mean        0.50000  \n",
       "std         0.50025  \n",
       "min         0.00000  \n",
       "25%         0.00000  \n",
       "50%         0.50000  \n",
       "75%         1.00000  \n",
       "max         1.00000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import \"Classified Data\", set the index_col to 0\n",
    "df = pd.read_csv(\"data/Classified Data\",index_col=0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"standardizing-features\"></a>\n",
    "## Standardizing Features\n",
    "---\n",
    "\n",
    "There is one major issue that applies to many machine learning models: They are sensitive to feature scale. \n",
    "\n",
    "> KNN in particular is sensitive to feature scale because it (by default) uses the Euclidean distance metric. To determine closeness, Euclidean distance sums the square difference along each axis. So, if one axis has large differences and another has small differences, the former axis will contribute much more to the distance than the latter axis.\n",
    "\n",
    "This means that it matters whether our feature are centered around zero and have similar variance to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use a scaler from sklearn\n",
    "\n",
    "##Import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##Instantiate\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit + transform\n",
    "scaled_features = scaler.fit_transform(df.drop(\"TARGET CLASS\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the new column to the df\n",
    "df_feat = pd.DataFrame(scaled_features, columns = df.columns[:-1])\n",
    "df_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, df[\"TARGET CLASS\"],\n",
    "                                                   test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using kNN\n",
    "Remember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "#Fit\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a K value\n",
    "How do we make sure we can choose a good K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... seems like a lot of work... why not...\n",
    "#from sklearn import grid_search\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k = np.arange(100) + 1\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': k}\n",
    "\n",
    "#Note! CV should be no more than 25% of the data!\n",
    "gs = GridSearchCV(    \n",
    "    estimator= knn,\n",
    "    param_grid= params,\n",
    "    cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "#Check the documentation! How do you get only the best k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now with K = ?\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp =confusion_matrix(y_test,pred).ravel()\n",
    "\n",
    "print('WITH K=5')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print('Confusion Matrix Expanded')\n",
    "print('True Negative:{}'.format(tn), 'False Positive:{}'.format(fp))\n",
    "print('False Negative:{}'.format(fn), 'True Positive:{}'.format(tp))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
