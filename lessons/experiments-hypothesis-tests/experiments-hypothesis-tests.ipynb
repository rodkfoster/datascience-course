{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Experiments and Hypothesis Testing\n",
    "\n",
    "_Authors: Alexander Egorenkov (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- Explain the purpose and steps in hypothesis testing\n",
    "- Determine causality and sampling bias using Directed Acyclic Graphs\n",
    "- Define the null and alternative hypotheses.\n",
    "- Perform a two-sample t-test.\n",
    "- Define the t-statistics and p-value.\n",
    "- Identify what missing data is and how to handle it\n",
    "- Test a hypothesis using a sample case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Data Source](#data-source)\n",
    "\t- [What Are the Features/Covariates/Predictors?](#what-are-the-featurescovariatespredictors)\n",
    "\t- [What Is the Outcome/Response?](#what-is-the-outcomeresponse)\n",
    "\t- [What Do You Think Each Row in the Data Set Represents?](#what-do-you-think-each-row-in-the-dataset-represents)\n",
    "- [Math Review](#math-review)\n",
    "\t- [Covariance](#covariance)\n",
    "\t- [Correlation](#correlation)\n",
    "\t- [The Variance-Covariance Matrix](#the-variance-covariance-matrix)\n",
    "- [Causation and Correlation](#causation-and-correlation)\n",
    "\t- [Structure of Causal Claims](#structure-of-causal-claims)\n",
    "\t- [Why Do We Care?](#why-do-we-care)\n",
    "\t- [How Do We Determine if Something is Causal?](#how-do-we-determine-if-something-is-causal)\n",
    "- [The Pearlean Causal DAG Model](#pearlean-causal-dag-model)\n",
    "\t- [What Is a DAG?](#what-is-a-dag)\n",
    "\t- [X Causes Y](#its-possible-that-x-causes-y)\n",
    "\t- [Y Causes X](#y-causes-x)\n",
    "\t- [The Correlation Between X and Y Is Not Statistically Significant](#the-correlation-between-x-and-y-is-not-statistically-significant)\n",
    "\t- [X or Y May Cause One or the Other Indirectly Through Another Variable](#x-or-y-may-cause-one-or-the-other-indirectly-through-another-variable)\n",
    "\t- [There is a Third Common Factor That Causes Both X and Y](#there-is-a-third-common-factor-that-causes-both-x-and-y)\n",
    "\t- [X and Y Cause a Third Factor, But Our Data Collect the Third Factor Unevenly](#both-x-and-y-cause-a-third-variable-and-the-dataset-does-not-represent-that-third-variable-evenly)\n",
    "\t- [Controlled Experiments](#controlled-experiments)\n",
    "\t- [When Is it OK to Rely on Association?](#when-is-it-ok-to-rely-on-association)\n",
    "\t- [How Does Association Relate to Causation?](#how-does-association-relate-to-causation)\n",
    "- [Sampling Bias](#sampling-bias)\n",
    "\t- [Forms of Sampling Bias](#forms-of-sampling-bias)\n",
    "\t- [Problems From Sampling Bias](#problems-from-sampling-bias)\n",
    "\t- [Recovering From Sampling Bias](#recovering-from-sampling-bias)\n",
    "    - [Stratified Random Sampling](#stratified-random-sampling)\n",
    "- [Missing Data](#missing-data)\n",
    "\t- [Types of Missing Data](#types-of-missing-data)\n",
    "\t- [De Minimis](#de-minimis)\n",
    "\t- [Class Imbalance](#class-imbalance)\n",
    "    - [Over and Under Sampling](#over-under-sample)\n",
    "    - [Relation to Machine Learning](#relation-to-machine-learning)\n",
    "- [Introduction to Hypothesis Testing](#introduction-to-hypothesis-testing)\n",
    "\t- [Validate Your Findings](#validate-your-findings)\n",
    "\t- [Confidence Intervals](#confidence-intervals)\n",
    "\t- [Error Types](#error-types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific Method\n",
    "\n",
    "In general our Data Science workflow follows an approach mirroring the scientific method\n",
    "\n",
    "**1. Question**<br>\n",
    "**2. Hypothesis**<br>\n",
    "**3. Experiment**<br>\n",
    "**4. Observation**<br>\n",
    "**5. Analysis**<br>\n",
    "**6. Conclusion**<br>\n",
    "<br>\n",
    "\n",
    "To allow ourselves to come back to a data driven decision - we need to approach our area of study by setting up a reliable, reproducible/repeatable framework. Key to that is building out a data science \"laboratory\" governed by a few rules. The first is building an effective hypothesis\n",
    "\n",
    "### Rules of Experiments\n",
    "1. Must show that a hypothesis is **Supported** or **Not Supported**\n",
    "2. Results must be **Measurable** and **Objective**\n",
    "3. Must be **Repeatable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-source\"></a>\n",
    "## Data Source\n",
    "\n",
    "---\n",
    "\n",
    "Today, we’ll use advertising data from an example in the book [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/).\n",
    "- This is a well-known, standard introduction to machine learning.\n",
    "- The book has a more advanced version — [Elements of Statistical Learning](http://web.stanford.edu/~hastie/ElemStatLearn/) — if you are comfortable with linear algebra and statistics at the graduate level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code-Along: Bring in Today's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:52:12.574145Z",
     "start_time": "2020-05-04T19:52:12.568127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This allows plots to appear directly in the notebook.\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.449237Z",
     "start_time": "2020-05-04T19:40:05.364464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data into a DataFrame.\n",
    "\n",
    "# We use index_col to tell Pandas that the first column in the data has row labels.\n",
    "advertising = pd.read_csv('./data/advertising.csv')\n",
    "advertising.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.459210Z",
     "start_time": "2020-05-04T19:40:05.452230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the data with .head(). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this new device. The company might ask you the following: \"On the basis of this data, how should we spend our advertising money in the future?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-are-the-featurescovariatespredictors\"></a>\n",
    "### What are the Features/Covariates/Predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.775365Z",
     "start_time": "2020-05-04T19:40:05.463199Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-21b50beca36f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Answer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTV\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mRadio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNewspaper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TV' is not defined"
     ]
    }
   ],
   "source": [
    "# Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-the-outcomeresponse\"></a>\n",
    "### What Is the Outcome/Response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.779353Z",
     "start_time": "2020-05-04T19:40:03.452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-do-you-think-each-row-in-the-dataset-represents\"></a>\n",
    "### What Do You Think Each Row in the Data Set Represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.781350Z",
     "start_time": "2020-05-04T19:40:03.456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"math-review\"></a>\n",
    "## Math Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"covariance\"></a>\n",
    "### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance is a measure of the joint variability between two random variables.\n",
    "\n",
    "You can think of this as a measure of linear association. If you have a variance of Y and a variance of X, the covariance is the amount of variance they share.\n",
    "\n",
    "$$cov(X, Y) = \\frac {\\sum{(x_i - \\bar{X})(y_i - \\bar{Y})}} {n}$$\n",
    "\n",
    "#### The math can be a bit intimidating, but I show it only to ask these two questions:\n",
    "\n",
    "* When will covariance be positive?\n",
    "* How will outliers affect covariance?\n",
    "\n",
    "> We can gain insight into covariance by looking closely at the formula above. First, observe that the formula effectively pairs the first $x$ data point with the first $y$ data point: $(x_1, y_1)$. All computations are done solely on these pairs of points.\n",
    "\n",
    "> Second, let's ask ourselves, **when would covariance be positive**? From the numerator, covariance would be positive if, for all pairs of data points, $(x_i - \\bar{X})$ and $(y_i - \\bar{Y})$ are 1) both positive or 2) both negative. This occurs when: 1) Both data points are greather than their respective means. Or when: 2) Both data points are less than their respective means! So, if the $x$ data points vary from their mean in the same way the $y$ data points vary from their mean, covariance will be positive.\n",
    "\n",
    "> Third, let's consider: **Might outliers affect covariance?** Yes! Given the structure of the formula (a sum of terms), a large outlier pair far from the means could strongly pull the covariance in one direction.\n",
    "\n",
    "\n",
    "**A Useful Special Case (Used Below)**\n",
    "\n",
    "$$cov(X, X) = \\frac {\\sum{(x_i - \\bar{X})^2}} {n} = var(X) = \\sigma_X^2$$\n",
    "\n",
    "\n",
    "### Principles of Covariance\n",
    "1. **Bilinearity.** Covariance is directly proportional to the scale of X and Y.\n",
    "\n",
    "2. **Correlation.** Covariance increases as the points approximate an upward sloping line and decreases as the points approximate a downward sloping line.\n",
    "\n",
    "3. **Linear Associations.** Because non-linear associations can create mixtures of positives and negatives, they lead to unpredictable (and not very useful) covariances.\n",
    "\n",
    "4. **Outlier Sensitivity.** Given the structure of the formula (a sum of terms), a large outlier pair far from the means could strongly pull the covariance in one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"correlation\"></a>\n",
    "### Correlation\n",
    "\n",
    "While covariance is a useful measure, it can be difficult to compare covariances, as they are not standardized. \n",
    "\n",
    "Instead we can use the correlation, which measures the same effect but reports it as a range from -1 to 1. 1 represents perfect covariance and correlation, 0 represents no correlation, and -1 one represents perfect inverse correlation.\n",
    "\n",
    "$$corr(X,Y) = \\frac {cov(X,Y)} {\\sigma_X\\sigma_Y} = \\frac {\\mathbb{E}[(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}])(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}])]} {\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "Note that the variance is always positive, making the denominator positive. So, the sign of the covariance between $X$ and $Y$ is the same as the sign of their correlation! \n",
    "\n",
    "The following visual examples better illustrate how correlation refers to how $X$ and $Y$ change together. Notice that a correlation number by itself is not always indicative of the relationship between the variables — always try to supplement 2-D correlation with a visual!\n",
    "\n",
    "![](./assets/images/correlation_examples.png)\n",
    "\n",
    "\n",
    "Another familiar way to look at correlation, with R-squared (Note: The square root of R-squared is the correlation coefficient):\n",
    "\n",
    "<img src=\"./assets/images/Correlation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-variance-covariance-matrix\"></a>\n",
    "### The Variance-Covariance Matrix\n",
    "\n",
    "For our purposes in modeling and machine learning, the fastest way to get a preview of the underlying relationships in our data is to use the variance-covariance matrix.\n",
    "\n",
    "The variance-covariance matrix shows the covariance between every variable in our data set.\n",
    "\n",
    "If you have many $x$-variables, it's common to organize covariances into a **var-covar matrix** (sometimes just called a **covariance matrix**).\n",
    "\n",
    "Given $n$ features from $X_1$ to $X_n$, the variance-covariance matrix looks like this (recall that $cov(X, X) = var(X)$):\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \n",
    "\\left[ \\begin{array}{c}\n",
    "\\text{Var}(X_1) & \\text{Cov}(X_1,X_2) & \\cdots & \\text{Cov}(X_1,X_n)  \\\\\n",
    "\\text{Cov}(X_2,X_1) & \\text{Var}(X_2) & \\cdots & \\text{Cov}(X_2,X_n)  \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(X_n,X_1) & \\text{Cov}(X_n,X_2) & \\cdots & \\text{Var}(X_n)\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "From a quick glance at this matrix, we can glean insight about which variables might be strongly correlated. This may also indicate redundant features and/or affect some models.\n",
    "\n",
    "If data are centered around the mean, every column has its mean subtracted from itself. So, the mean for every column is now 0. You can then compute the variance-covariance matrix as:\n",
    "\n",
    "$$\\frac {X^TX} {n}$$\n",
    "\n",
    "Those of you who have been exposed to linear regression may recognize this term.\n",
    "\n",
    "But... still not useful right? We can't read covariances easily. So it's also common to have a **correlation matrix**:\n",
    "\n",
    "$$\n",
    "\\mathbf{R} = \n",
    "\\begin{bmatrix}\n",
    "1 & \\text{Corr}(X_1, X_2) & \\cdots & \\text{Corr}(X_1, X_n) \\\\\n",
    "\\text{Corr}(X_2, X_1) & 1 & \\cdots & \\text{Corr}(X_2, X_n) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Corr}(X_n, X_1) & \\text{Corr}(X_n, X_2) & \\cdots & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Calculate the variance-covariance matrix. Make sure to first de-mean the data:\n",
    "\n",
    "##### Or.... use the DataFrame's built-in .cov() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.782346Z",
     "start_time": "2020-05-04T19:40:03.463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.784341Z",
     "start_time": "2020-05-04T19:40:03.468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer using built-in cov() method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the correlation matrix using the DataFrame's built-in `.corr()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.787333Z",
     "start_time": "2020-05-04T19:40:03.473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a large amount of data, the correlation matrix may be too difficult to read. It can help to make a plot.\n",
    "\n",
    "#### Use Seaborn's `.heatmap()` function to make a plot of the correlation matrix.\n",
    "\n",
    "- Remember that we imported Seaborn as `sns`.\n",
    "- To make a correlation matrix from a DataFrame, try `my_df.corr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.793317Z",
     "start_time": "2020-05-04T19:40:03.478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, use the Seaborn `.clustermap` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.794314Z",
     "start_time": "2020-05-04T19:40:03.488Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, looking at linear association doesn't show us the whole picture. We can get a more detailed look with a scatterplot matrix.\n",
    "\n",
    "#### Use Seaborn's `.pairplot()` function to make joint scatterplots of the data.\n",
    "\n",
    "- See if you can guess or [figure out](http://seaborn.pydata.org/generated/seaborn.pairplot.html) how `pairplot()` might work.\n",
    "- `pairplot()` plots each column against each column of a DataFrame. So, at the minimum you must have to pass in the DataFrame you want to analyze!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.796309Z",
     "start_time": "2020-05-04T19:40:03.494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"causation-and-correlation\"></a>\n",
    "## Causation and Correlation\n",
    "---\n",
    "\n",
    "**Objective**: Explain the difference between causation and correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Think of various examples of studies you’ve seen in the media related to food:\n",
    "    - \"Study links coffee consumption to decreased risk of colorectal cancer\"\n",
    "    - \"Coffee does not decrease risk of colorectal cancer\"\n",
    "    - \"Diapers, Beer and Data Science in Retail\"\n",
    "    \n",
    "There's a whole book series based on these [Spurious Correlations](http://www.tylervigen.com/spurious-correlations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, why are these spurious correlations so common?**\n",
    "\n",
    "- Sensational Headlines\n",
    "- Professor's need to publish, publish, publish!\n",
    "- There's a neglect of robust data analysis.\n",
    "- Causal claims and associations are difficult to convey in an unambiguous way.\n",
    "\n",
    "The coffee claims above are **correlated** but may or may not be **causal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"structure-of-causal-claims\"></a>\n",
    "### Structure of Causal Claims\n",
    "\n",
    "- If X happens, Y must happen.\n",
    "- If Y happens, X must have happened.\n",
    "  - (You need X and something else for Y to happen.)\n",
    "- If X happens, Y will probably happen.\n",
    "- If Y happens, X probably happened.\n",
    "\n",
    "> **Note:** Properties from definitions are not causal. If some a shape is a triangle, it's implied that it has three sides. However, it being a triangle does not _cause_ it to have three sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"why-do-we-care\"></a>\n",
    "### Why Do We Care?\n",
    "\n",
    "- Understanding this difference is critical for executing the data science workflow, especially when identifying and acquiring data.\n",
    "- We need to fully articulate our question and use the right data to answer it while also considering any **confounders**.\n",
    "\n",
    "> **Confounders** are unobserved variables that could affect the outcome. If we neglect to include confounding variables in an analysis, we could easily produce an inaccurate model. For example, we might falsely assume that eating more ice cream cones causes us to wear fewer layers of clothing. In actuality, eating ice cream is correlated with a confounding variable — temperature! To perform an accurate analysis, we can only conclude that ice cream consumption is _correlated with_ clothing layers.\n",
    "\n",
    "- We don’t want to overstate what our model measures.\n",
    "- Be careful not to say “caused” when you really mean “measured” or “associated.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-do-we-determine-if-something-is-causal\"></a>\n",
    "### How Do We Determine if Something is Causal?\n",
    "\n",
    "Considering causal criteria is one approach to assessing causal relationships.\n",
    "\n",
    "However, it’s hard to define universal causal criteria.\n",
    "\n",
    "One attempt that's commonly used in the medical field is based on work by Bradford Hill.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He developed a list of “tests” that an analysis must pass in order to indicate a causal relationship:\n",
    "\n",
    "\n",
    "- Strength of association\n",
    "- Consistency\n",
    "- Specificity\n",
    "- Temporality\n",
    "- Biological gradient\n",
    "- Plausibility\n",
    "- Coherence\n",
    "- Experiment\n",
    "- Analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strength (effect size)**: A small association does not mean that there is not a causal effect, although the larger the association, the more likely the effect is to be causal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consistency (reproducibility)**: Consistent findings observed by different persons in different places with different samples strengthens the likelihood of an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity**: Causation is likely if there is a very specific population at a specific site and a disease with no other likely explanation. The more specific an association between a factor and an effect, the greater the probability of a causal relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temporality**: The effect has to occur after the cause (and, if there is an expected delay between the cause and expected effect, then the effect must occur after that delay)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Biological gradient**: Greater exposure should generally lead to greater incidence of the effect. However, in some cases, the mere presence of the factor can trigger the effect. In other cases, an inverse proportion is observed: greater exposure leads to lower incidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plausibility**: A plausible mechanism between cause and effect is helpful (but Hill noted that knowledge of the mechanism is limited by current knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coherence**: Coherence between epidemiological and laboratory findings increases the likelihood of an effect. However, Hill noted that \"... lack of such [laboratory] evidence cannot nullify the epidemiological effect on associations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**: \"Occasionally it is possible to appeal to experimental evidence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analogy**: The effect of similar factors may be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pearlean-causal-dag-model\"></a>\n",
    "## The Pearlean Causal Directed Acyclic Graph (DAG) Model\n",
    "\n",
    "---\n",
    "### Some Quick Background Notes:\n",
    "\n",
    "- This model is a visual tool to help us reason about causality and association.\n",
    "- It was proposed by Judea Pearl, although there are many similar models.\n",
    "- We will only scratch the surface, so look into other resources if you're interested in learning more.\n",
    "    - We'll cover the basic idea and most notable cases.\n",
    "    - We won't talk about the formal mathematics or underlying probability, or how to use d-seperation to infer causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-a-dag\"></a>\n",
    "### What Is a DAG?\n",
    "- DAG stands for directed acyclic graph; it's a collection of nodes connected by lines. \n",
    "- Each line has an arrow to point in a direction.\n",
    "- If you follow the arrows, you reach a final node. There are no loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single circle or node in a causal DAG represents an event; something that happens at one point in time.\n",
    "\n",
    "![](./assets/images/dag1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend random variables X and Y — or two different types of events — are correlated with each other.\n",
    "\n",
    "**What are the possible causal structures that would produce this correlation?**\n",
    "\n",
    "- X causes Y.\n",
    "- Y causes X.\n",
    "- There is no actual causation.\n",
    "- X or Y indirectly causes the other.\n",
    "- There is a third factor that causes both.\n",
    "- X and Y cause a third factor, but our data collect the third factor unevenly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"its-possible-that-x-causes-y\"></a>\n",
    "### X causes Y.\n",
    "![](./assets/images/x-cause-y.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"y-causes-x\"></a>\n",
    "### Y causes X.\n",
    "![](./assets/images/y-cause-x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-correlation-between-x-and-y-is-not-statistically-significant\"></a>\n",
    "### The correlation between X and Y is not statistically significant.\n",
    "![](./assets/images/xy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"x-or-y-may-cause-one-or-the-other-indirectly-through-another-variable\"></a>\n",
    "### X or Y may cause one or the other indirectly through another variable.\n",
    "![](./assets/images/x-c-z-y.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"there-is-a-third-common-factor-that-causes-both-x-and-y\"></a>\n",
    "### There is a third common factor that causes both X and Y.\n",
    "![](./assets/images/z-cause-xy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"both-x-and-y-cause-a-third-variable-and-the-dataset-does-not-represent-that-third-variable-evenly\"></a>\n",
    "### X and Y cause a third factor, but our data collect the third factor unevenly.\n",
    "\n",
    "![](./assets/images/xy-causez.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, recovering the causality structure from a correlation matrix is difficult or at times impossible. However, thinking through causal effects can give you a much better intuition regarding your variables and your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is a \"Confounder\"?\n",
    "\n",
    "Let’s say we performed an analysis to understand what causes lung cancer. \n",
    "\n",
    "We find that people who carry cigarette lighters are 2.4 times more likely to contract lung cancer than people who don’t carry lighters.\n",
    "\n",
    "Does this mean that the lighters are causing cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've noted before, if lighters and cancer are both caused by smoking, there will be a correlation between lighters and cancer. This isn't the only possible diagram, but it makes the most sense.\n",
    "![](./assets/images/smoke-lighter-cancer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we believe the structure above, conditioning on smoking by only looking at non-smokers removes the correlation between lighters and cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"controlled-experiments\"></a>\n",
    "### Controlled Experiments\n",
    "\n",
    "- The most foolproof way to measure an effect is to control all of the confounders and directly intervene and control our variable of interest. \n",
    "- This way we know that any correlation we find is not because of the confounders but instead because of the variable we control. \n",
    "- This also means that all the effects we see are due to the variable we control.\n",
    "- However, experiments are not always possible and take longer than using observational data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"when-is-it-ok-to-rely-on-association\"></a>\n",
    "### When Is it OK to Rely on Association?\n",
    "\n",
    "- **When any intervention that arises from your model affects only the outcome variable.**\n",
    "    - In other words, you only need to predict Y.\n",
    "    - This works because we only need to observe explanatory variables and implicitly know the confounders' effect.\n",
    "    - Decision-making and intervention based on your model are hidden dangers that can shift confounders.\n",
    "    - You can always retrain your model to work with a new set of confounders if they shift.\n",
    "\n",
    "- **When correlation is causal.**\n",
    "    - If you are sure there are no confounding factors or selection bias, then that association might be a causation (risky).\n",
    "    - It's OK to exclude confounders that have very unlikely or small effects.\n",
    "    - This is a saving grace. To create a good model, you only need variables that correlate with your outcome.\n",
    "        - Those variables merely need to meaningfully correlate with your outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-does-association-relate-to-causation\"></a>\n",
    "### How Does Association Relate to Causation?\n",
    "\n",
    "- Most commonly, we find an association between two variables.\n",
    "    - There is an observed correlation between the variables.\n",
    "    - There is an observed correlation in a subset of data.\n",
    "    - We find that the descriptive statistics significantly differ in two subsets of data.\n",
    "\n",
    "- We may not still fully understand the causal direction (e.g., does smoking cause cancer or does cancer cause smoking?).\n",
    "    - A causes B, B causes A, or a third factor causes both.\n",
    "        - A and B never cause each other!\n",
    "\n",
    "- We also might not understand other factors influencing the association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confounding variables often hide the true association between causes and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A directed acyclic graph (DAG) can help determine which variables are most important for your model. It helps to visually demonstrate the logic of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code-Along: Explore the Associations in the Advertising Data\n",
    "\n",
    "#### Visualize the relationship between the features and the response using scatterplots.\n",
    "\n",
    "- Below, we filled in how to make a scatterplot for the columns `sales` vs `TV`. \n",
    "- Using this as an example, can you also make scatterplots for `sales` vs `radio` and `sales` vs `newspaper`?\n",
    "- `axs[0]` is the first coordinate grid, `axs[1]` is the second coordinate grid, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.797306Z",
     "start_time": "2020-05-04T19:40:03.538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the relationship between the features and the response using scatterplots:\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "\n",
    "advertising.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(10, 6));\n",
    "\n",
    "# Add in the next two plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a relationship between ads and sales? Which type of ads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.799301Z",
     "start_time": "2020-05-04T19:40:03.543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we say this a causal relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.802293Z",
     "start_time": "2020-05-04T19:40:03.550Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What other questions might we want to know about this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:40:05.804288Z",
     "start_time": "2020-05-04T19:40:03.553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Exercise: Evaluate Which Type of Ad is Associated With Higher Sales\n",
    "\n",
    "Let's say we want to evaluate which type of ad is associated with higher sales.\n",
    "\n",
    "1. Draw a basic DAG on your table or whiteboard.\n",
    "    - Think about other variables that may predict sales.\n",
    "    - Think about confounders.\n",
    "    - Think about the downstream effects changing investment in advertising.\n",
    "    - Be ready to share an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section Summary\n",
    "\n",
    "1) **It's importlant to have deep subject area knowledge.** You'll develop this over time and it will help you move through your analysis in a logical manner. However, keep in mind that you can show a strong association and still be wrong.\n",
    "\n",
    "2) **A DAG (directed acyclic graph) can be a handy tool for thinking through the logic of your models.**\n",
    "\n",
    "3) **There is a distinction between causation and correlation.** In our smoking example, it's relatively obvious that there's a flaw in our logic; however, this won't always be so readily apparent — especially in cutting-edge fields where there are many other unknown variables.\n",
    "\n",
    "4) **Good data are essential.** Throughout this course we will be developing your data intuition so you can spot gaps and bias more readily. You'll also be introduced to tools that can help. However, your analysis is only as good as your understanding of the problem and the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sampling-bias\"></a>\n",
    "## Sampling Bias\n",
    "---\n",
    "\n",
    "**Sampling bias** occurs when a sample is collected in such a way that some members of the intended population are more or less likely to be included than others.\n",
    "\n",
    "This can happen when a sample is taken non-randomly — either implicitly or explicitly.\n",
    "\n",
    "When we have non-random sampling that results in sampling bias, it can affect the inferences or results of our analyses. We must be sure not to attribute our results to the process we observe when they could actually be because of non-random sampling.\n",
    "\n",
    "Conceptually, this is straightforward: **When we have sampling bias, we aren't measuring what we think we are measuring.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"forms-of-sampling-bias\"></a>\n",
    "### Examples of Sampling Bias\n",
    "\n",
    "- **Pre-screening:** Purposely restricting the sample to a specific group or region.\n",
    "    - This typically happens when people try to study priority areas to save costs and assume priority areas are the same as random areas.\n",
    "- **Self-selection:** When someone has the ability to non-randomly decide what is included in a sample.\n",
    "    - This typically happens in surveys and polls but can also be an issue with other kinds of reporting.\n",
    "- **Survivorship bias:** When we select only surviving subjects in a sample over time.\n",
    "    - This might happen when we only look at existing customers and assume they have the same characteristics as new customers.\n",
    "    \n",
    "    \n",
    "### Exercise: Team up and determine a potential real example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problems-from-sampling-bias\"></a>\n",
    "### Problems That Arise From Sampling Bias\n",
    "- We could overestimate or underestimate means and sample statistics for simple characteristics.\n",
    "- It's possible to have artificial correlation where there should be none.\n",
    "\n",
    "If you wanted to get the average height of the residents of Washington, DC, would you only sample the Washington Wizards?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"recovering-from-sampling-bias\"></a>\n",
    "### Recovering From Sampling Bias\n",
    "- Working out causal DAGs can help you identify when to watch out for sampling bias.\n",
    "- Generally, it's best to prevent sampling bias whenever possible.\n",
    "- We can't really do anything if we ENTIRELY exclude an important group of data.\n",
    "- However, if portions of our data are overrepresented or underrepresented, there are ways to correct that effect.\n",
    "    - Typically, we explicitly model the selection process, which means we need data on factors that determine whether  or not someone participates.\n",
    "    - **Account for it**: If certain portions of the data are over/underrepresented, we can account for this.\n",
    "        - The field of **survey methodology** is built around gaining insights from data collected in interesting ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stratified-random-sampling\"></a>\n",
    "### Stratified Random Sampling\n",
    "\n",
    "Sometimes it's better to sample certain subpopulations specifically. You can perform an SRS within **strata** of the population.  This is called **stratified random sampling** and if it's done well, it can yield better insights than an SRS on the whole populations.\n",
    "\n",
    "- **Stratified random sampling** ensures we capture important population characteristics in the random sample. If we know that the population is half males and half females, for example, we can make sure that our sample is half male and half female. We effectively break the population into two \"strata\" (groups), then randomly sample from each group to obtain our overall sample. This method is similar to taking a weighted average and depends on knowing key population statistics.\n",
    "    - For example, if we are collecting survey data, we might ensure our participants are evenly split between men and women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-data\"></a>\n",
    "## Missing Data\n",
    "---\n",
    "\n",
    "Sometimes we are unable to collect every attribute for a particular observation.\n",
    "\n",
    "Unfortunately, this makes the observation unusable until we decide how to deal with it.\n",
    "\n",
    "**We have to decide whether to:**\n",
    "    - Drop the observation.\n",
    "    - Drop the attribute.\n",
    "    - Impute a value for that specific attribute and observation.\n",
    "\n",
    "**So, how do we decide?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de-minimis\"></a>\n",
    "### De Minimis\n",
    "- If few enough observations are missing, it's not likely to change our results to a meaningful degree.\n",
    "- In these cases, we don't have to bother with trivialities and simply pick a method that works well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"types-of-missing-data\"></a>\n",
    "### Types of Missing Data\n",
    "\n",
    "- **Missing completely at random (MCAR)**\n",
    "    - The reason that the data are missing is completely random and introduces no sampling bias.\n",
    "    - In this case, it's safe to drop or impute.\n",
    "    - We can test for this by looking at other attributes for missing and non-missing groups to see if they match.\n",
    "\n",
    "- **Missing at random (MAR)**\n",
    "    - The data are missing in a way that is related to another factor.\n",
    "    - This is a form of sampling bias.\n",
    "    - Like other instances of sampling bias, we can fix this by modeling the selection process.\n",
    "        - This is done by building a model to impute the missing value based on other variables.\n",
    "\n",
    "- **Missing not at random (MNAR)**\n",
    "    - The response is missing in a way that relates to its own value.\n",
    "    - We can't test for this.\n",
    "    - We also can't fix this in a reasonable way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"class-imbalance\"></a>\n",
    "### Class Imbalance\n",
    "\n",
    "Sometimes a sample may include an overrepresentation of one type of class. For example, airport security may have 990 X-ray scans showing the absence of a weapon. Due to natural scarcity, it may only provide 10 scans showing a weapon.\n",
    "\n",
    "- If our goal is to create a model that indicates whether or not a weapon is present, then we are at a disadvantage. **Ignoring the class imbalance** would lead to a model that always guesses that a weapon is not present!\n",
    "    - Note that most optimization procedures optimize for training data accuracy. Always guessing that a weapon is absent leads to 990/1000 correct results; an accuracy of 99 percent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:37:27.447839Z",
     "start_time": "2020-05-04T20:37:27.390986Z"
    }
   },
   "source": [
    "<a id=\"over-under-sample\"></a>\n",
    "### Undersampling & Oversampling \n",
    "\n",
    "![](./assets/images/resampling.png)\n",
    "- A simple way to address class imbalance is to **undersample** the majority class, deliberately leaving us with a balanced data set of 10 each. However, this is less than ideal, as it effectively ignores much of the available data.\n",
    "\n",
    "\n",
    "- Alternatively, we could **oversample** the minority class by duplicating examples. Again, this is not ideal. Because we have very little data, this will magnify small differences that may just be errors, leading to a model that overfits.\n",
    "\n",
    "\n",
    "It is highly suggested to learn about the various methods available to you to accomplish both approaches along with their concepts. This [overview on the kaggle website](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets) will walk you through a range of topics to include:\n",
    "1. Imbalanced datasets\n",
    "2. The metric trap\n",
    "3. Resampling\n",
    "- Random under-sampling\n",
    "- Random over-sampling\n",
    "- Python imbalanced-learn module\n",
    "- Random under-sampling and over-sampling with imbalanced-learn\n",
    "- Under-sampling: Tomek links\n",
    "- Under-sampling: Cluster Centroids\n",
    "- Over-sampling: SMOTE\n",
    "- Over-sampling followed by under-sampling\n",
    "- Additional Recommended reading\n",
    "\n",
    "Later in the course, we will look at additional methods for training models to work around class imbalance. For example, we may use an optimization algorithm that cares less about accuracy and more about minimizing particular types of errors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relation-to-machine-learning\"></a>\n",
    "### Relation to Machine Learning\n",
    "\n",
    "Many of the topics discussed in this lesson are used in both statistics and machine learning. However, some of the terminology differs. \n",
    "\n",
    "Throughout this lesson, we have discussed **variables** (typically **independent variables** and **dependent variables**). For example, we might be given the **linear estimator** $Y = mX + b$. We could say that this contains two variables ($X$ - independent and $Y$ - dependent (i.e., the prediction, as it depends on $X$)), a coefficient of $m$, and the constant of $b$.\n",
    "\n",
    "In machine learning, we typically rewrite this as a function — $\\hat{y}(x) = mx + b$ — and call it a **linear model**. The predicted value is $\\hat{y}(x)$ (\"prediction\" is denoted by the carat), which is dependent on $x$. We might call $x$ a **feature** rather than a variable.\n",
    "\n",
    "> **Example:** Suppose a house price $P$ is linearly dependent on its square footage $S$. So, we might predict $P = cS + b$, where $c$ and $b$ are constants. Alternatively, we could write $\\hat{p}(s) = cs + b$. Here, we took a complicated house and modeled it using a single feature — its square footage. Of course, we are likely missing many confounding variables/features that also affect the price! So, our model likely contains a lot of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction-to-hypothesis-testing\"></a>\n",
    "## Introduction to Hypothesis Testing\n",
    "---\n",
    "\n",
    "**Objective**: Test a hypothesis within a sample case study.\n",
    "\n",
    "You'll remember that we've worked previously on descriptive statistics such as mean and variance. How would we tell if there is a difference between our groups? How would we know if this difference was real or if our finding is simply the result of chance?\n",
    "\n",
    "After taking a random sample at Acme, men on average spend \\\\$60. Women on average spend \\\\$70 . Are these two numbers **significantly different**?\n",
    "- Do we have enough information to know (No, we don't).\n",
    "- Are these findingds indicative of a real trend, or are they by chance?\n",
    "\n",
    "For example, if we are working on sales data, how would we know if there was a difference between the buying patterns of men and women at Acme, Inc.? **Hypothesis testing!**\n",
    "\n",
    "### Four steps to hypothesis testing\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion.\n",
    "\n",
    "\n",
    "\n",
    "### Examples of Hypotheses\n",
    "- The sales in California are greater than the sales in Texas.\n",
    "- Customer Segment A will have a larger response than Segment B to a specific marketing strategy.\n",
    "- Changing the subject line of an email will boost sales by 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validate-your-findings\"></a>\n",
    "## Validate Your Findings\n",
    "\n",
    "#### How Do We Tell if the Association We Observed is Statistically Significant?\n",
    "\n",
    "**Statistical significance** is whether or not a result or relationship is caused by something other than mere random chance. Statistical hypothesis testing is traditionally employed to determine whether or not a result is statistically significant.\n",
    "\n",
    "We might ask: **How likely is the effect observed to be true, assuming the null hypothesis is true?** If the probability of our observation occurring by chance is less than 5 percent (supposing the null hypothesis), then we reject the null hypothesis. _(Note that the 5 percent value is in many ways arbitrary)._\n",
    "\n",
    "The probability of our observations occurring by chance, given the null hypothesis, is the **p-value** ($p$).\n",
    "\n",
    "---\n",
    "\n",
    "**Example:** Suppose you flip a coin three times and get three heads in a row. These three flips are our observations.\n",
    "\n",
    "+ We want to know whether or not the coin is fair. So, we select the **null hypothesis:**\n",
    "<br><br>\n",
    "$$H_0: \\text{The coin is fair.}$$\n",
    "<br>\n",
    "+ Now, let's suppose the null hypothesis is true. Three heads in a row occurs with a chance of $1/2^3 \\approx 12.5\\%$.\n",
    "+ Because there is a reasonable ($> 5\\%$) chance of three heads occuring naturally, we do not reject the null hypothesis.\n",
    "+ So, **we conclude** that we do not have enough data to tell whether or not the coin is fair ($p = 0.125$).\n",
    "\n",
    "---\n",
    "\n",
    "In other words, we say that something is NOT statistically significant if there is a less than 5 percent chance that our finding was caused by chance alone (assuming the null hypothesis is true)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, suppose that we flipped the coin ten times and received all 10 heads. The probability of this occuring is $1/2^10 = 1/1024$, which is below $5\\%$. In this case, we **would reject the null hypothesis and conclude the coin is unfair**.\n",
    "\n",
    "Hopefully the logic shines through here:\n",
    "- 3 heads in a row isn't rare. It can happen.\n",
    "- 10 heads in a row is extremely unlikely. I'd believe the coin was unfair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided practice: hypothesis testing for coin flips\n",
    "\n",
    "Let's say we want to test whether a coin is rigged to turn up more heads when flipping. What's our null hypothesis? How would we simulate this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:41:45.536587Z",
     "start_time": "2020-05-04T19:41:45.510657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = 100000\n",
    "np.random.seed(3)\n",
    "# as we increase the sample size, we approach a normal distribution\n",
    "data = np.random.randint(2, size = (trials,30)) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:41:25.195617Z",
     "start_time": "2020-05-04T19:41:25.186642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 18, 17, ..., 12, 19, 17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = np.sum(data, axis = 1) # sum up the number of heads in rows (experiments)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:41:25.744108Z",
     "start_time": "2020-05-04T19:41:25.517713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(N)\n",
    "plt.title('1000 Coins, 30 Tosses Each', fontsize = 20)\n",
    "plt.xlabel('number of heads', fontsize = 14)\n",
    "plt.ylabel('number of trials', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we flipped our real-life coin 30 times, and saw 20 heads. What is the probability of this given $H_0$, which we model with a fair coin? We can use our simulation and simply count the proportion of times we observed a result at least as large as the one we're interested in.\n",
    "\n",
    "First, let's pick an $\\alpha$ **significance level**: at what point do we say a result is improbable enough that we won't believe it happened in a world where $H_0$ is true?\n",
    "\n",
    "$$\\alpha = ?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:41:48.405428Z",
     "start_time": "2020-05-04T19:41:48.153097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04996 0.05 False\n"
     ]
    }
   ],
   "source": [
    "alpha = .05\n",
    "pval = sum(N >= 20) / trials\n",
    "\n",
    "print(pval, alpha, pval > alpha)\n",
    "\n",
    "# This gives ~5% chance, just above our alpha level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing Steps\n",
    "\n",
    "As we walk through hypothesis testing we'll frame an example to add some additional context. In this case say we are testing the efficacy of a new drug on blood pressure:\n",
    "\n",
    "- Studies cost a lot - so, we randomly select 50 people to be in the placebo control condition and 50 people to receive the treatment.\n",
    "    - In the context of experiments, we often talk about the \"control\" group and the \"experimental\" or \"treatment\" group.\n",
    "    - In our example, the control group is the one given the placebo (sugar pill) and the treatment group is the one given the actual drug.\n",
    "    \n",
    "    #### We are interested in the average difference in blood pressure levels between the treatment and control groups.\n",
    "    - We know our sample is selected from a broader, unknown population pool.\n",
    "    - We can imagine that, in a hypothetical parallel world, we could have ended up with a different random sample of subjects from the population pool.\n",
    "        - Thus, we can assume there is some variability in the statistics we get from our sample.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment findings so far\n",
    "\n",
    "Say that, in our drug experiment, we measure the following results:\n",
    "\n",
    "- The 50 subjects in the control group have an average systolic blood pressure of 121.38.\n",
    "- The 50 subjects in the experimental/treatment group have an average systolic blood pressure of 111.56.\n",
    "\n",
    "The difference between experimental and control samples is -9.82 points. \n",
    "\n",
    "**But**, with only 50 subjects in each sample, how confident can we be that this measured difference is real? \n",
    "- Do we have enough evidence to say that the population average blood pressure is different between these two groups?\n",
    "\n",
    "\n",
    "We can perform what is known as a **$t$-test** to evaluate this. (A $t$-test is one of many, many types of [hypothesis tests](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can set up the experimental and control observations below as `numpy` arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:05:17.885168Z",
     "start_time": "2020-05-04T20:05:17.876188Z"
    }
   },
   "outputs": [],
   "source": [
    "control = np.array([166, 165, 120,  94, 104, 166,  98,  85,  97,  87, 114, 100, 152,\n",
    "                    87, 152, 102,  82,  80,  84, 109,  98, 154, 135, 164, 137, 128,\n",
    "                    122, 146,  86, 146,  85, 101, 109, 105, 163, 136, 142, 144, 140,\n",
    "                    128, 126, 119, 121, 126, 169,  87,  97, 167,  89, 155])\n",
    "\n",
    "experimental = np.array([ 83, 100, 123,  75, 130,  77,  78,  87, 116, 116, 141,  93, 107,\n",
    "                         101, 142, 152, 130, 123, 122, 154, 119, 149, 106, 107, 108, 151,\n",
    "                         97,  95, 104, 141,  80, 110, 136, 134, 142, 135, 111,  83,  86,\n",
    "                         116,  86, 117,  87, 143, 104, 107,  86,  88, 124,  76])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:05:18.907897Z",
     "start_time": "2020-05-04T20:05:18.900914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.819999999999993"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the average of the control and experimental groups\n",
    "\n",
    "# print the difference of the sample means, too\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Construct a Null Hypothesis\n",
    "Generally speaking, we start with a **null hypothesis** and an **alternative hypothesis**, which is the opposite of the null. Then, you check whether the data support rejecting your null hypothesis or fail to reject the null hypothesis.\n",
    "\n",
    "For example:\n",
    "\n",
    "- **Null hypothesis**: Typically denoted as $H_0$ states there is no relationship between the variables. This is a statement you want to contradict with your findings\n",
    "- **Alternative hypothesis**: There is a relationship\n",
    "\n",
    "\n",
    "For our experiment, we will set up a null hypothesis and an alternative hypothesis:\n",
    "\n",
    "- $H_0$: The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is 0.\n",
    "\n",
    "- $H_A$: The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is NOT 0.\n",
    "\n",
    "Note that **\"failing to reject\"** the null hypothesis is not the same as **\"accepting\"** it. Your alternative hypothesis may indeed be true, but you don't necessarily have enough data to show that yet.\n",
    "\n",
    "This distinction is important for helping you avoid overstating your findings. You should only state what your data and analysis can truly represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:04:44.670341Z",
     "start_time": "2020-05-04T20:04:44.663361Z"
    }
   },
   "source": [
    "Likewise, our measured difference is **-9.82**.\n",
    "\n",
    "Written out using probability notation, we want to know:\n",
    "\n",
    "### $$P(\\text{data}\\;|\\;H_0 \\text{ true})$$\n",
    "\n",
    "**What is the probability that we observed this data, assuming that our null hypothesis is true?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Specify the level of significance\n",
    "\n",
    "If we assume that our null hypothesis is true, and the probability of observing the data we observed is \"small,\" then our data does not support our null hypothesis. \n",
    "\n",
    "**But how \"small\" is small enough?**\n",
    "\n",
    "This is set by our level of significance, which we call $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically (and arbitrarily) the value $\\alpha=0.05$ is used.\n",
    "- This means that there is a 5% chance that we will _incorrectly reject the null hypothesis_ (a.k.a. Type 1 error or false positive).\n",
    "- Put another way, there is a 5% chance that we will claim a significant difference in blood pressure between the two groups when in fact there is no (statistically significant) difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Calculate your Test Statistic\n",
    "\n",
    "Hypothesis testing is a \"box\" where the inputs are our data and the outputs allow us to make our decision \n",
    "- Well, in this \"box,\" we are calculating $P(\\text{data}\\;|\\;H_0 \\text{ true})$. \n",
    "- This calculation requires picking a probability distribution, then comparing the results of our experiment to this distribution to see how extreme our results are relative to the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:56:16.324604Z",
     "start_time": "2020-05-04T19:56:16.317623Z"
    }
   },
   "source": [
    "When comparing two means, the **t-statistic** (based on the [Student's $t$-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)) is a classic way to quantify the difference between groups. \n",
    "- In essence, our $t$-statistic is be a standardized version of the difference between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But, let's take a quick look at the mathematical details of the calculation of the $t$-statistic anyway.\n",
    "\n",
    "When comparing the difference between groups, we can calculate the two-sample $t$-statistic like so:\n",
    "\n",
    "$$t = \\frac{\\bar{x}_E - \\bar{x}_C}{\\sqrt {s^2 \\Big(\\frac{1}{n_E} + \\frac{1}{n_C}\\Big)}}$$\n",
    "\n",
    "> In our example, $\\bar{x}_E$ is the mean of our experimental group's sample measurements and $\\bar{x}_C$ is the mean of our control group's sample measurements.\n",
    ">\n",
    "> $n_E$ and $n_C$ are the number of observations in each group. \n",
    ">\n",
    "> The $s^2$ denotes our *sample variance*. In this version of the $t$-test, we are assuming equal variances in our experimental and control groups in the overall population. There is another way to calculate the $t$-test where equal variance is not assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample variance is calculated like so:\n",
    "\n",
    "$$ s^2 = \\frac{\\sum_{i=1}^{n_E} (x_i - \\bar{x}_E)^2 + \\sum_{j=1}^{n_C} (x_j - \\bar{x}_C)^2}{ n_E + n_C -2} $$\n",
    "\n",
    "> This combines the variance of the two groups' measurements into a single pooled metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:15:39.766282Z",
     "start_time": "2020-05-04T20:15:39.760296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.8915462966190273, pvalue=0.06161817112302221)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct your t-test\n",
    "stats.ttest_ind(experimental, control, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare the output of our test to our threshold and interpret our decision\n",
    "\n",
    "$P(Data | H_0)$\n",
    "\n",
    "The **p-value** is the probability that, **GIVEN THE NULL HYPOTHESIS IS TRUE**, we would observe the current set of data. \n",
    "\n",
    "#### How to think about hypothesis testing\n",
    "\n",
    "The p-value is $P(Data | H_0)$. If this probability is below some *significance level* cut-off ($\\alpha$), then we **reject** the null hypothesis; otherwise, we **fail to reject** it.\n",
    "\n",
    "There is a rich body of inferential statistics that allows us to calculate this analytically using *parametric methods*, i.e. given certain assumptions. This is the traditional way of doing hypothesis tests.\n",
    "\n",
    "If we have a model of $H_0$, we can sometimes also calculate this directly with simulations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do we make the decision?\n",
    "\n",
    "Remember that $\\alpha$ is our level of significance.\n",
    "\n",
    "- If $p\\text{-value} < \\alpha$, then there is evidence to reject the null hypothesis, so you accept that $H_0$ is incorrect and therefore $H_A$ is correct.\n",
    "    - i.e., a statisically significant difference between the two groups!\n",
    "    - This is like saying there is enough evidence to say our dog isn't innocent... so we say our dog is guilty.\n",
    "- If $p\\text{-value} \\ge \\alpha$, then there is insufficient evidence to reject the null hypothesis and you cannot accept that either $H_0$ or $H_A$ is correct.\n",
    "    - i.e., there is no statistical difference between your two groups.\n",
    "    - This is like saying there is not enough evidence to say our dog isn't innocent. We can't totally determine that our dog is innocent, but we haven't determined that our dog is guilty, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So what was our decision?\n",
    "\n",
    "Since the p-value of 0.06 is greater than our cutoff of 0.05 then there is insufficient evidence to reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR What are we doing?\n",
    "\n",
    "**GOAL:** To tell whether or not our new treatment is effective. \n",
    "- We define \"effective\" as whether or not those who get the treatment see lower systolic blood pressure, on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we follow the following steps to carry out a **hypothesis test**:\n",
    "1. Set up null and alternative hypotheses. In pure math terms that, looks like this:\n",
    "\n",
    "> $$ H_0: \\mu_{\\text{treatment}} - \\mu_{\\text{placebo}} = 0 $$\n",
    "> $$ H_A: \\mu_{\\text{treatment}} - \\mu_{\\text{placebo}} \\ne 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decide on a significance level. \n",
    "> $\\alpha = 0.05$ is a typical choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Decide on a hypothesis test (there are thousands of them). \n",
    "> In this case, we're testing the difference between two means, which is a great time to use a **two-sample $t$-test**.\n",
    ">\n",
    "> - The two-sample (independent) $t$-test tests whether or not two population means differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. After carrying out this hypothesis test, we'll see if our data provide enough evidence to reject the null hypothesis.Typically by comparing the p-value to our significance threshold (alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:36:30.662501Z",
     "start_time": "2020-05-04T19:36:30.648535Z"
    }
   },
   "source": [
    "### There are two broad strategies for testing hypotheses:\n",
    "\n",
    "The first is **Simulation-based**:\n",
    "- Describe null and alternative hypotheses\n",
    "- Set significance level alpha\n",
    "- Define model\n",
    "- Run simulation\n",
    "- Calculate p-value\n",
    "- Compare p-value to alpha\n",
    "\n",
    "![](./assets/images/Hypothesistestingfigure.png)\n",
    "_Image from http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second **Parametric methods**:\n",
    "- Describe null and alternative hypotheses\n",
    "- Set significance level alpha\n",
    "- Define distribution\n",
    "- Calculate test statistic\n",
    "- Calculate p-value\n",
    "- Compare p-value to alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:29:11.992094Z",
     "start_time": "2020-05-04T19:29:11.959184Z"
    }
   },
   "source": [
    "## Other Hypothesis Test Statistics\n",
    "The goal of this lesson was to teach you, in general, how hypothesis testing works. We showed you what is probably the most common variety of hypothesis test: the $t$-test. However, there are many others available. It's not worth our time to go over so many more of them, as they all have the same implementation and interpretation, just in different situations. Instead, here is a list of many of the \"big\" ones and when to use them:\n",
    "\n",
    "| Situation | Common hypothesis test | Example | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| Testing whether or not one mean is equal to a value | One-sample $t$-test | Do cars on a given road, on average, drive about 65mph? | |\n",
    "| Testing whether or not two means are equal to eachother | Two-sample $t$-test | Is the mean systolic blood pressure of people who receive Medicine A or Medicine B the same? | |\n",
    "| Testing whether or not paired observations have the same value | Paired $t$-test | Among heterosexual married couples, is the husband, on average, taller than the wife? | This is functionally the same as a one-sample $t$-test of the differences |\n",
    "| Testing whether or not three or more means are the same | One-way ANOVA test | Are base salaries upon graduation different for graduates of Penn State, Ohio State, and Michigan? | The ANOVA test has many variants |\n",
    "| Testing whether or not there is a relationship between two categorical variables | $\\chi^2$ test | Is there a relationship between home state and political affiliation? | |\n",
    "| Testing whether or not a given distribution is normally distributed | Kolmogorov-Smirnov Test | Testing whether or not model residuals are normally distributed. Useful for testing linear regression assumptions! | |\n",
    "| Testing whether or not one proportion is equal to a number | One-sample $z$-test | Testing whether or not a coin is fair (ie, testing $P(Heads) = 0.5$) | |\n",
    "| Testing whether or not two proportions are euqal | Two-sample $z$-test | Who is going to win an election? | Testing two or more proportions can be done better with a $\\chi^2$ test |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"confidence-intervals\"></a>\n",
    "### Confidence Intervals\n",
    "\n",
    "A closely related concept tp **p-values** is **confidence intervals**. A 95 percent confidence interval can be interpreted like so: under infinite sampling of the population, we would expect that the true value of the parameter we are estimating to fall within that range 95% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that we only have a **single sample of data** and not the **entire population of the data**. The \"true\" effect/difference is either within this interval or it is not. We have no firm knowledge, however, that our single estimate of the \"true\" effect/difference is close or not to the \"truth\". The confidence interval around our estimate tells us, with a given sample size and level of confidence, the range in which future estimates are likely to fall.\n",
    "\n",
    "Note that using 95 percent confidence intervals is just a convention. You can create 90 percent confidence intervals (which will be more liberal), 99 percent confidence intervals (which will be more conservative), or whatever intervals you prefer.\n",
    "\n",
    "\n",
    "<img src=\"assets/images/Conf_interval.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"error-types\"></a>\n",
    "### Error Types\n",
    "\n",
    "Statisticians often classify errors not just as errors but as one of two specific types of errors — type I and type II.\n",
    "\n",
    "+ **Type I errors** are false positives.\n",
    "    - Machine learning: Our model falsely predicts \"positive.\" (The prediction is incorrect.)\n",
    "    - Statistics: Incorrect rejection of a true null hypothesis.\n",
    "\n",
    "\n",
    "+ **Type II errors** are false negatives.\n",
    "    - Machine learning: Our model falsely predicts \"negative.\" (The prediction is incorrect.)\n",
    "    - Statistics: Incorrectly retaining a false null hypothesis.\n",
    "\n",
    "\n",
    "Understanding these errors can be especially beneficial when designing models. For example, we might decide that type I errors are OK but type II errors are not. We can then optimize our model appropriately.\n",
    "\n",
    "> **Example:** Suppose we make a model for airline security in which we predict whether or not a weapon is present (\"positive\"). In this case, we would much rather have type I errors (falsely predict a weapon) than type II errors (falsely predict no weapon).\n",
    "\n",
    "> **Example:** Suppose we make a model for the criminal justice system in which we whether or not a defendant is guilty (\"positive\"). In this case, we would much rather have type II errors (falsely predict innocent) than type I errors (falsely predict guilty).\n",
    "\n",
    "<img src=\"assets/images/Type1_2_errors.png\">\n",
    "\n",
    "\n",
    "Can you phrase these examples in terms of null hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Differences Between Business and Statistics\n",
    "* **We typically ignore measurement error**- What is a customer? Timing (Database entry vs. actual time)\n",
    "<br>\n",
    "<br>\n",
    "* **Tons of data!** Many variables and models will be significant using traditional statistical methods.\n",
    "<br>\n",
    "<br>\n",
    "* **Time Dependency**- Businesses change over time and seasons (ice cream in winter vs. summer), whereas statistics should be absolutely repeatable. (other factors may not be apparent (confounders)\n",
    "<br>\n",
    "<br>\n",
    "* **Business experiments generally cost a lot more** than scientific experiments, and could have greater impact.\n",
    "<br>\n",
    "<br>\n",
    "* **Data is often incomplete** (censored or truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions/Summary\n",
    "\n",
    "* **Hypothesis Testing**: What is it used for?\n",
    "    - It's often used for _differentiating things_. Today we used it to tell apart two categories. We'll soon use HTs for another purpose: model selection.\n",
    "    - Steps:\n",
    "        1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "        2. Specify a level of significance.\n",
    "        3. Calculate your test statistic.\n",
    "        4. Find your $p$-value and make a conclusion.\n",
    "* **Confidence Intervals**: What are they used for?\n",
    "    - Giving ranges of feasible values. When HTs answer yes/no questions, CIs answer open-ended, quantitative ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Practice\n",
    "Let's break into groups to dig into some practice examples [Hypothesis Lab](./practice/AB_testing/AB_testing.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
